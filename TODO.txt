

Final goals:

    0. Single-machine ELM that does all of the below
    1. Solve Big Data tasks
        1a. Out-of-memory algorithms
        1b. Accelerated solvers
        1c. Distributive solution
    2. Use any types of neurons
    3. Use regularizations and prunings
    4. Use classification
    5. Work with timeseries
    6. Unbalanced data
    7. Balance matrix H with different types of inputs

######################################################################


List of desired behaviour

    1. Solve XOR problem with 'sigm' ELM
    2. Solve Sine problem with 'sigm' ELM
    3. Types of single input neurons: linear, 'sigm', 'tanh'
    4. Types of two-input neurons: 'rbf_l2', 'rbf_l1', 'rbf_linf'
    5. Save and load ELM model
    


List of advanced behaviour - general ELM model

    1. Normalizations in solution: TROP
    2. Accelerated neuron computing 
    3. Matlab integration
    4. Proper multiclass support
    5. ??? Arbitrary neurons
    6. !!! Timeseries !!!



List of advanced desired behaviour - small data ELM

    1. MSE_PRESS error for classification
    2. Neuron pruning: MRSR, MRSR2



List of advanced desired behaviour - huge data ELM

    1. Based on HDF5 data
    2. Distributed computing of the result
    3. Distributed MSE error for classification
    4. High performance solvers (MAGMA)
    5. Information criteria for neuron pruning
    6. ??? Parallel I/O



List of additional tools

    1. Normalization parameters calculator
    2. Class encoder/decoder
    3. RBF neurons sampler: random, given, kNN
    4. Kernel neurons helper
    5. Get data about saved ELM model


#####################################################################


    H = []
    for neuron in neurons:
        H0 = project(X, neuron.W, neuron.b, neuron.kind)
        H0 = neuron.ufunc(H0)
        H.append(H0)
    H = np.hstack(H)        

    # project(X,W,b,"sigm") = X.dot(W) + b
    # project(X,W,b,"rbf_l2") = cdist(X,W,"l2") / -2*(b**2)

